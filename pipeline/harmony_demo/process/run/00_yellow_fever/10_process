#!/bin/bash -eu
set -o pipefail

# load the utilities file to use the 'setupenvforpypy' command.
source "${pipeline_utils_dir}/bash/common.sh"

# enters the pypy virtual environment for better performance.
setupenvforpypy

# this data will still need to be process by the shared steps, so put it in
# the temp directory for intermediate outputs.
pushd "${pipeline_tmp_dir}" &> /dev/null

# clear past processed data if step is run multiple times.
rm -rf "${pipeline_tmp_dir}"/*

# the process_csv script takes in data in the zenysis base format, cleans it,
# and transforms it into the optimal format for final processing. to explain
# each input parameter:
#   delimiter: the data is semicolon delimited.
#   rename_cols: rename the dimensions into their platform names. use the
#     input municipality code column so it is 1) unique (some municipalities
#     in different states have the same name) and 2) easier to map to the
#     canonical name.
#   date: this input column holds the date.
#   prefix: use the source id for the field prefix.
#   sourcename: this should match the source id used for the process folder.
#   set_cols: this file did not have an input field column. create one by
#     creating the column "cases" and setting its value as 1 for all rows.
#   fields: this data is in the pivoted format, so list the field columns. use
#     the "cases" field that was created.
#   input: use the same file that was fetched in 00_fetch.
#   output_locations: this output file can be used to get all locations matched.
#   output_fields: this output file lists all field ids that were found in the
#     data.
#   output_rows: this output file contains the processed data rows.
"${pipeline_src_root}/data/pipeline/scripts/process_csv.py" \
  --delimiter ';' \
  --rename_cols 'cod_mun_lpi:municipalityname' 'sexo:sex' 'idade:age' 'obito:death' \
  --date 'dt_is' \
  --prefix 'yellow_fever' \
  --sourcename 'yellow_fever' \
  --set_cols 'cases:1' 'test_indicator:5'\
  --fields 'cases' 'test_indicator'\
  --input="${pipeline_feed_dir}/yellow_fever_cases.csv" \
  --output_locations="${pipeline_tmp_dir}/locations.csv" \
  --output_fields="${pipeline_tmp_dir}/fields.csv" \
  --output_rows="${pipeline_tmp_dir}/processed_data.json.lz4"

popd &> /dev/null
